{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi6wEFi3or9BGfyX2Xx520",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhiqbalalamin/DeepLearning-UAS/blob/main/Chapter_7_Teori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble Learning dan Random Forest**"
      ],
      "metadata": {
        "id": "Tq9hJ74MfRG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apa Itu Ensemble Learning?\n",
        "Ensemble Learning adalah teknik yang menggabungkan beberapa model Machine Learning (prediktor) untuk meningkatkan akurasi prediksi. Kumpulan model ini disebut ensemble, sementara cara penggabungannya disebut metode ensemble.\n",
        "\n",
        "Contoh:\n",
        "\n",
        "* Menggabungkan beberapa Decision Tree menjadi satu model prediktif yang lebih kuat, yaitu Random Forest.\n",
        "\n",
        "## Voting Classifier\n",
        "Hard Voting:\n",
        "\n",
        "* Setiap model memberikan prediksi kelas.\n",
        "\n",
        "* Kelas yang paling sering dipilih akan menjadi prediksi akhir.\n",
        "\n",
        "Soft Voting:\n",
        "\n",
        "* Setiap model memberikan probabilitas untuk setiap kelas.\n",
        "\n",
        "* Probabilitas dijumlahkan, dan kelas dengan rata-rata probabilitas tertinggi akan dipilih.\n",
        "\n",
        "Metode ensemble akan lebih efektif apabila model-model penyusunnya beragam dan relatif independen.\n",
        "\n",
        "## Bagging dan Pasting\n",
        "Bagging (Bootstrap Aggregating):\n",
        "\n",
        "* Setiap model dilatih pada subset acak dari data pelatihan dengan pengembalian (replacement).\n",
        "\n",
        "Pasting:\n",
        "\n",
        "* Serupa dengan Bagging, namun dilakukan tanpa pengembalian.\n",
        "\n",
        "Kedua teknik ini bertujuan untuk mengurangi variance tanpa meningkatkan bias secara signifikan.\n",
        "\n"
      ],
      "metadata": {
        "id": "p-oJw-s6fSnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluasi Out-of-Bag (OOB)\n",
        "Dalam metode Bagging, setiap model hanya dilatih pada sebagian data pelatihan.\n",
        "Data yang tidak digunakan (disebut out-of-bag) dapat dimanfaatkan untuk mengevaluasi performa model tanpa memerlukan validation set tambahan.\n",
        "\n",
        "## Random Patches dan Random Subspaces\n",
        "* Random Patches: melakukan sampling baik pada fitur maupun instance.\n",
        "\n",
        "* Random Subspaces: melakukan sampling hanya pada fitur.\n",
        "\n",
        "Kedua pendekatan ini meningkatkan keragaman model dan mengurangi korelasi antar prediktor.\n",
        "\n",
        "## Random Forest\n",
        "Random Forest merupakan kumpulan Decision Tree yang dibentuk menggunakan:\n",
        "\n",
        "* Teknik Bagging\n",
        "\n",
        "* Pemilihan fitur secara acak pada setiap pemisahan (split)\n",
        "\n",
        "Pendekatan ini menghasilkan model yang lebih beragam, menurunkan variance, dan tetap menjaga bias pada tingkat yang rendah.\n",
        "\n",
        "## Extra-Trees (Extremely Randomized Trees)\n",
        "Mirip dengan Random Forest, namun memiliki dua perbedaan utama:\n",
        "\n",
        "* Menggunakan threshold secara acak untuk melakukan split, bukan memilih split terbaik\n",
        "\n",
        "* Lebih cepat karena tidak mencari pemisahan optimal\n",
        "\n",
        "Tambahan elemen acak ini mempercepat pelatihan dan membantu mengurangi variance.\n",
        "\n",
        "## Feature Importance\n",
        "Random Forest dapat digunakan untuk mengukur tingkat kepentingan fitur, berdasarkan:\n",
        "\n",
        "* Seberapa besar pengurangan impurity yang dihasilkan oleh setiap fitur\n",
        "\n",
        "Nilai kepentingan fitur kemudian dinormalisasi agar totalnya sama dengan 1.\n",
        "\n",
        "## Boosting\n",
        "Boosting adalah metode ensemble di mana model dilatih secara berurutan, dan setiap model baru berusaha memperbaiki kesalahan dari model sebelumnya.\n",
        "\n",
        "Dua varian populer:\n",
        "\n",
        "* AdaBoost\n",
        "\n",
        "* Gradient Boosting\n",
        "\n"
      ],
      "metadata": {
        "id": "2_W4fTQofkHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaBoost (Adaptive Boosting)\n",
        "Cara kerja:\n",
        "\n",
        "1. Bobot setiap instance diinisialisasi secara merata\n",
        "\n",
        "2. Latih model, lalu hitung kesalahan berbobot\n",
        "\n",
        "3. Tingkatkan bobot untuk instance yang salah diklasifikasikan\n",
        "\n",
        "4. Latih model berikutnya\n",
        "\n",
        "5. Gabungkan seluruh model menggunakan voting berbobot\n",
        "\n",
        "### Rumus Kesalahan Tertimbang:\n",
        "\\[\n",
        "$r_j = \\frac{\\sum_{i=1}^{m} w_i \\cdot \\mathbf{1}(y_i \\neq h_j(x_i))}{\\sum_{i=1}^{m} w_i}$\n",
        "\\]\n",
        "\n",
        "### Bobot Model:\n",
        "\n",
        "\\[\n",
        "$\\alpha_j = \\eta \\cdot \\log\\left( \\frac{1 - r_j}{r_j} \\right)$\n",
        "\\]\n",
        "\n",
        "### Update Bobot Instance:\n",
        "\n",
        "\\[\n",
        "$w_i \\leftarrow w_i \\cdot \\exp(\\alpha_j) \\quad \\text{jika salah}$\n",
        "\\]\n",
        "\n",
        "### Prediksi Final:\n",
        "\n",
        "\\[\n",
        "$\\hat{y}(x) = \\arg\\max_k \\sum_{j=1}^{N} \\alpha_j \\cdot \\mathbf{1}(h_j(x) = k)$\n",
        "\\]"
      ],
      "metadata": {
        "id": "6Z8GGfJif8NV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting\n",
        "Gradient Boosting juga membangun model secara berurutan, namun alih-alih mengubah bobot instance, pendekatan ini berfokus pada mengurangi residual (sisa kesalahan) dari model sebelumnya.\n",
        "\n",
        "### Fungsi Tujuan (Regresi dengan MSE):\n",
        "\\[\n",
        "$\\hat{y}_m(x) = \\hat{y}_{m-1}(x) + \\eta \\cdot h_m(x)$\n",
        "\\]\n",
        "\n",
        "- \\($ h_m(x) $\\): model ke-m yang memprediksi residual\n",
        "- \\($ \\eta $\\): learning rate (pengontrol langkah perbaikan)\n",
        "\n",
        "### Early Stopping:\n",
        "Pelatihan dihentikan ketika error validasi mulai meningkat, guna menghindari overfitting.\n",
        "\n",
        "## XGBoost (Extreme Gradient Boosting)\n",
        "XGBoost adalah implementasi Gradient Boosting yang:\n",
        "\n",
        "* Cepat dan efisien\n",
        "\n",
        "* Mendukung early stopping, pelatihan paralel, serta regularisasi\n",
        "\n",
        "* Sangat populer dalam kompetisi seperti Kaggle\n",
        "\n",
        "## Stacking (Stacked Generalization)\n",
        "Alih-alih melakukan voting, Stacking menggunakan model tambahan (disebut meta-learner atau blender) untuk menggabungkan prediksi dari beberapa model dasar.\n",
        "\n",
        "Langkah-langkah:\n",
        "\n",
        "1. Latih beberapa model dasar pada subset data\n",
        "\n",
        "2. Gunakan prediksi mereka untuk membentuk dataset baru\n",
        "\n",
        "3. Latih model meta pada dataset hasil prediksi tersebut\n",
        "\n",
        "Metode ini sering kali memberikan akurasi yang lebih tinggi dibandingkan teknik voting biasa."
      ],
      "metadata": {
        "id": "4V1i5ABGgOv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kesimpulan**\n",
        "* Ensemble Learning dapat secara signifikan meningkatkan performa model\n",
        "\n",
        "* Bagging efektif dalam mengurangi variance, sedangkan Boosting menekan bias\n",
        "\n",
        "* Random Forest adalah model yang kuat dan fleksibel berbasis Decision Tree\n",
        "\n",
        "* Stacking menawarkan pendekatan penggabungan yang lebih kompleks dan akurat\n",
        "\n",
        "* Gunakan cross-validation untuk menentukan strategi ensemble terbaik pada suatu masalah\n",
        "\n",
        "# **Referensi**\n",
        "GÃ©ron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly Media."
      ],
      "metadata": {
        "id": "svtxTbvRgm_9"
      }
    }
  ]
}