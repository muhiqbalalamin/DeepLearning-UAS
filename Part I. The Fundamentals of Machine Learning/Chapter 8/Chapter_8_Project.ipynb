{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGDtMDj+N38HUKGn3H5PRU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhiqbalalamin/DeepLearning-UAS/blob/main/Chapter_8_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persiapan"
      ],
      "metadata": {
        "id": "mK3kUjUnm_LI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekXNAbRJmsvR"
      },
      "outputs": [],
      "source": [
        "# Cek versi Python dan Scikit-Learn\n",
        "import sys, sklearn\n",
        "assert sys.version_info >= (3, 5)\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Import umum\n",
        "import numpy as np, os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Konfigurasi global\n",
        "np.random.seed(42)\n",
        "%matplotlib inline\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Setup path penyimpanan gambar\n",
        "IMAGES_PATH = \"./images/dim_reduction\"\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, ext=\"png\", dpi=300):\n",
        "    path = os.path.join(IMAGES_PATH, f\"{fig_id}.{ext}\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=ext, dpi=dpi)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "3ebZZfUanBJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 3D sintetis dengan noise\n",
        "np.random.seed(4)\n",
        "m, w1, w2, noise = 60, 0.1, 0.3, 0.1\n",
        "\n",
        "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "X = np.empty((m, 3))\n",
        "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
        "X[:, 2] = X[:, 0]*w1 + X[:, 1]*w2 + noise * np.random.randn(m)\n",
        "\n",
        "# SVD manual untuk reduksi dimensi\n",
        "X_centered = X - X.mean(axis=0)\n",
        "U, s, Vt = np.linalg.svd(X_centered)\n",
        "X2D_svd = X_centered @ Vt.T[:, :2]\n",
        "\n",
        "# PCA dari Scikit-Learn\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "X2D_pca = pca.fit_transform(X)\n",
        "\n",
        "# Validasi kesamaan hasil SVD dan PCA\n",
        "print(\"SVD vs PCA (identik, beda tanda):\", np.allclose(X2D_pca, -X2D_svd))\n",
        "\n",
        "# Rekonstruksi ke 3D dari 2D\n",
        "X3D_inv_pca = pca.inverse_transform(X2D_pca)\n",
        "X3D_inv_svd = X2D_svd @ Vt[:2, :]\n",
        "\n",
        "# Evaluasi rekonstruksi\n",
        "print(\"Rata-rata error rekonstruksi (PCA):\", np.mean(np.sum((X - X3D_inv_pca)**2, axis=1)))\n",
        "print(\"Kesamaan hasil inverse SVD & PCA (tanpa mean):\", np.allclose(X3D_inv_svd, X3D_inv_pca - pca.mean_))\n",
        "\n",
        "# Komponen utama\n",
        "print(\"PCA Components:\\n\", pca.components_)\n",
        "print(\"SVD Vt[:2]:\\n\", Vt[:2])"
      ],
      "metadata": {
        "id": "zEZ-FGQpnEeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explained Variance Ratio"
      ],
      "metadata": {
        "id": "73VQk0H4nJBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.patches import FancyArrowPatch\n",
        "from mpl_toolkits.mplot3d import proj3d\n",
        "import os\n",
        "\n",
        "# Fungsi simpan gambar\n",
        "def save_fig(fig_id, tight_layout=True, ext=\"png\", dpi=300):\n",
        "    path = os.path.join(\"images\", \"dim_reduction\", f\"{fig_id}.{ext}\")\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=ext, dpi=dpi)\n",
        "\n",
        "# Setup visual\n",
        "np.random.seed(4)\n",
        "m, w1, w2, noise = 60, 0.1, 0.3, 0.1\n",
        "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "X = np.empty((m, 3))\n",
        "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m)/2\n",
        "X[:, 1] = np.sin(angles)*0.7 + noise * np.random.randn(m)/2\n",
        "X[:, 2] = X[:, 0]*w1 + X[:, 1]*w2 + noise * np.random.randn(m)\n",
        "\n",
        "X_centered = X - X.mean(axis=0)\n",
        "U, s, Vt = np.linalg.svd(X_centered)\n",
        "X2D_svd = X_centered @ Vt.T[:, :2]\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X2D = pca.fit_transform(X)\n",
        "X3D_inv = pca.inverse_transform(X2D)\n",
        "\n",
        "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
        "print(\"Lost Variance:\", 1 - pca.explained_variance_ratio_.sum())\n",
        "print(\"SVD Variance Proportion:\", np.square(s)/np.square(s).sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhQjg6UYnJne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.patches import FancyArrowPatch\n",
        "from mpl_toolkits.mplot3d import proj3d\n",
        "import os\n",
        "\n",
        "# Fungsi simpan gambar\n",
        "def save_fig(fig_id, tight_layout=True, ext=\"png\", dpi=300):\n",
        "    path = os.path.join(\"images\", \"dim_reduction\", f\"{fig_id}.{ext}\")\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=ext, dpi=dpi)\n",
        "\n",
        "# Kelas Arrow3D yang sudah diperbaiki\n",
        "class Arrow3D(FancyArrowPatch):\n",
        "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
        "        super().__init__((0, 0), (0, 0), *args, **kwargs)\n",
        "        self._verts3d = xs, ys, zs\n",
        "\n",
        "    def do_3d_projection(self, renderer=None):\n",
        "        xs3d, ys3d, zs3d = self._verts3d\n",
        "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, self.axes.M)\n",
        "        self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))\n",
        "        return np.min(zs)\n",
        "\n",
        "    def draw(self, renderer):\n",
        "        self.do_3d_projection(renderer)\n",
        "        super().draw(renderer)\n",
        "\n",
        "# Generate dataset 3D dengan noise\n",
        "np.random.seed(4)\n",
        "m, w1, w2, noise = 60, 0.1, 0.3, 0.1\n",
        "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "X = np.empty((m, 3))\n",
        "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m)/2\n",
        "X[:, 1] = np.sin(angles)*0.7 + noise * np.random.randn(m)/2\n",
        "X[:, 2] = X[:, 0]*w1 + X[:, 1]*w2 + noise * np.random.randn(m)\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "X2D = pca.fit_transform(X)\n",
        "X3D_inv = pca.inverse_transform(X2D)\n",
        "C = pca.components_\n",
        "\n",
        "# Split data untuk visualisasi\n",
        "X3D_above = X[X[:, 2] > X3D_inv[:, 2]]\n",
        "X3D_below = X[X[:, 2] <= X3D_inv[:, 2]]\n",
        "\n",
        "# Visualisasi\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Titik data asli dan proyeksi\n",
        "ax.plot(X3D_below[:, 0], X3D_below[:, 1], X3D_below[:, 2], \"bo\", alpha=0.5)\n",
        "ax.plot(X3D_above[:, 0], X3D_above[:, 1], X3D_above[:, 2], \"bo\")\n",
        "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k+\")\n",
        "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k.\")\n",
        "\n",
        "# Proyeksi garis dari titik ke rekonstruksi\n",
        "for i in range(m):\n",
        "    color = \"#505050\" if X[i, 2] <= X3D_inv[i, 2] else \"k\"\n",
        "    ax.plot([X[i, 0], X3D_inv[i, 0]], [X[i, 1], X3D_inv[i, 1]], [X[i, 2], X3D_inv[i, 2]], color)\n",
        "\n",
        "# Tambahkan panah vektor PCA\n",
        "arrow1 = Arrow3D([0, C[0, 0]], [0, C[0, 1]], [0, C[0, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\")\n",
        "arrow2 = Arrow3D([0, C[1, 0]], [0, C[1, 1]], [0, C[1, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\")\n",
        "ax.add_artist(arrow1)\n",
        "ax.add_artist(arrow2)\n",
        "\n",
        "# Label dan batas sumbu\n",
        "ax.set_xlabel(\"$x_1$\")\n",
        "ax.set_ylabel(\"$x_2$\")\n",
        "ax.set_zlabel(\"$x_3$\")\n",
        "ax.set_xlim([-1.8, 1.8])\n",
        "ax.set_ylim([-1.3, 1.3])\n",
        "ax.set_zlim([-1.0, 1.0])\n",
        "\n",
        "save_fig(\"dataset_3d_plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1NF2PniBnNN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(X2D[:, 0], X2D[:, 1], \"k.\")\n",
        "ax.plot([0], [0], \"ko\")\n",
        "ax.arrow(0, 0, 1, 0, head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
        "ax.arrow(0, 0, 0, 1, head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
        "ax.set_xlabel(\"$z_1$\")\n",
        "ax.set_ylabel(\"$z_2$\", rotation=0)\n",
        "ax.axis([-1.5, 1.3, -1.2, 1.2])\n",
        "ax.grid(True)\n",
        "save_fig(\"dataset_2d_plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZbqP7GlonP-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angle = np.pi / 5\n",
        "stretch = 5\n",
        "m = 200\n",
        "np.random.seed(3)\n",
        "X = np.random.randn(m, 2) / 10\n",
        "X = X @ np.array([[stretch, 0], [0, 1]])\n",
        "X = X @ np.array([[np.cos(angle), np.sin(angle)], [-np.sin(angle), np.cos(angle)]])\n",
        "u1 = np.array([np.cos(angle), np.sin(angle)])\n",
        "u2 = np.array([np.cos(angle - 2*np.pi/6), np.sin(angle - 2*np.pi/6)])\n",
        "u3 = np.array([np.cos(angle - np.pi/2), np.sin(angle - np.pi/2)])\n",
        "X_proj1 = X @ u1.reshape(-1, 1)\n",
        "X_proj2 = X @ u2.reshape(-1, 1)\n",
        "X_proj3 = X @ u3.reshape(-1, 1)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot2grid((3,2), (0, 0), rowspan=3)\n",
        "plt.plot(X[:, 0], X[:, 1], \"bo\", alpha=0.5)\n",
        "for u, style, label in zip([u1, u2, u3], [\"-\", \"--\", \":\"], [r\"$\\mathbf{c_1}$\", \"\", r\"$\\mathbf{c_2}$\"]):\n",
        "    plt.plot([-1.4, 1.4], [-1.4*u[1]/u[0], 1.4*u[1]/u[0]], f\"k{style}\", linewidth=2)\n",
        "plt.arrow(0, 0, u1[0], u1[1], head_width=0.1, fc='k', ec='k')\n",
        "plt.arrow(0, 0, u3[0], u3[1], head_width=0.1, fc='k', ec='k')\n",
        "plt.text(u1[0]+0.1, u1[1]-0.05, r\"$\\mathbf{c_1}$\", fontsize=22)\n",
        "plt.text(u3[0]+0.1, u3[1], r\"$\\mathbf{c_2}$\", fontsize=22)\n",
        "plt.axis(\"equal\")\n",
        "plt.grid(True)\n",
        "\n",
        "for i, Xp in enumerate([X_proj1, X_proj2, X_proj3]):\n",
        "    plt.subplot2grid((3,2), (i, 1))\n",
        "    plt.plot(Xp[:, 0], np.zeros(m), \"bo\", alpha=0.3)\n",
        "    plt.plot([-2, 2], [0, 0], \"k-\", linewidth=1)\n",
        "    plt.axis([-2, 2, -1, 1])\n",
        "    plt.grid(True)\n",
        "\n",
        "save_fig(\"pca_best_projection_plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f_J8T94-nRy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing the Right Number of Dimensions"
      ],
      "metadata": {
        "id": "7klVp4-mnVl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Fungsi simpan gambar\n",
        "def save_fig(fig_id, tight_layout=True, ext=\"png\", dpi=300):\n",
        "    path = os.path.join(\"images\", \"dim_reduction\", f\"{fig_id}.{ext}\")\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=ext, dpi=dpi)\n",
        "\n",
        "# Ambil dataset MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"].astype(np.uint8)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# PCA: hitung berapa dimensi untuk 95% variansi\n",
        "pca = PCA()\n",
        "pca.fit(X_train)\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "d = np.argmax(cumsum >= 0.95) + 1  # +1 karena indeks dimulai dari 0\n",
        "\n",
        "# Visualisasi variansi\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(cumsum, linewidth=3)\n",
        "plt.axis([0, 400, 0, 1])\n",
        "plt.xlabel(\"Dimensions\")\n",
        "plt.ylabel(\"Explained Variance\")\n",
        "plt.plot([d, d], [0, 0.95], \"k:\")\n",
        "plt.plot([0, d], [0.95, 0.95], \"k:\")\n",
        "plt.plot(d, 0.95, \"ko\")\n",
        "plt.annotate(\"Elbow\", xy=(65, 0.85), xytext=(70, 0.7),\n",
        "             arrowprops=dict(arrowstyle=\"->\"), fontsize=14)\n",
        "plt.grid(True)\n",
        "save_fig(\"explained_variance_plot\")\n",
        "plt.show()\n",
        "\n",
        "# Reduksi ke jumlah dimensi yang mempertahankan 95% variansi\n",
        "pca = PCA(n_components=0.95)\n",
        "X_reduced = pca.fit_transform(X_train)\n",
        "\n",
        "# Output hasil reduksi\n",
        "print(\"Jumlah komponen yang dipertahankan:\", pca.n_components_)\n",
        "print(\"Total variansi yang dijelaskan:\", np.sum(pca.explained_variance_ratio_))"
      ],
      "metadata": {
        "id": "zTncVRK-nXS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA for Compression"
      ],
      "metadata": {
        "id": "_X1nTd-jnYE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import os\n",
        "\n",
        "# Fungsi simpan gambar\n",
        "def save_fig(fig_id, tight_layout=True, ext=\"png\", dpi=300):\n",
        "    path = os.path.join(\"images\", \"dim_reduction\", f\"{fig_id}.{ext}\")\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=ext, dpi=dpi)\n",
        "\n",
        "# Reduksi dimensi ke 154 komponen dan kembalikan ke bentuk asli\n",
        "pca = PCA(n_components=154)\n",
        "X_reduced = pca.fit_transform(X_train)\n",
        "X_recovered = pca.inverse_transform(X_reduced)\n",
        "\n",
        "# Fungsi visualisasi grid digit\n",
        "def plot_digits(instances, images_per_row=5, **options):\n",
        "    size = 28\n",
        "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "    n_empty = n_rows * images_per_row - len(instances)\n",
        "    padded = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=0)\n",
        "    image_grid = padded.reshape((n_rows, images_per_row, size, size))\n",
        "    big_image = image_grid.transpose(0, 2, 1, 3).reshape(n_rows * size, images_per_row * size)\n",
        "    plt.imshow(big_image, cmap=mpl.cm.binary, **options)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Visualisasi original vs compressed\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.subplot(121)\n",
        "plot_digits(X_train[::2100])\n",
        "plt.title(\"Original\", fontsize=16)\n",
        "\n",
        "plt.subplot(122)\n",
        "plot_digits(X_recovered[::2100])\n",
        "plt.title(\"Compressed\", fontsize=16)\n",
        "\n",
        "save_fig(\"mnist_compression_plot\")\n",
        "plt.show()\n",
        "\n",
        "# Simpan hasil reduksi PCA untuk digunakan selanjutnya\n",
        "X_reduced_pca = X_reduced"
      ],
      "metadata": {
        "id": "fF22AMZ6ncXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomized PCA dan Incremental PCA"
      ],
      "metadata": {
        "id": "vzyOikQYndvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, time\n",
        "\n",
        "# Fungsi simpan gambar\n",
        "def save_fig(fig_id, tight_layout=True, ext=\"png\", dpi=300):\n",
        "    path = os.path.join(\"images\", \"dim_reduction\", f\"{fig_id}.{ext}\")\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=ext, dpi=dpi)\n",
        "\n",
        "# Visualisasi grid digit\n",
        "def plot_digits(instances, images_per_row=5, **options):\n",
        "    size = 28\n",
        "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "    n_empty = n_rows * images_per_row - len(instances)\n",
        "    padded = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=0)\n",
        "    image_grid = padded.reshape((n_rows, images_per_row, size, size))\n",
        "    big_image = image_grid.transpose(0, 2, 1, 3).reshape(n_rows * size, images_per_row * size)\n",
        "    plt.imshow(big_image, cmap=\"binary\", **options)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "n_batches = 100\n",
        "inc_pca = IncrementalPCA(n_components=154)\n",
        "for X_batch in np.array_split(X_train, n_batches):\n",
        "    inc_pca.partial_fit(X_batch)\n",
        "\n",
        "X_reduced_inc = inc_pca.transform(X_train)\n",
        "X_recovered_inc = inc_pca.inverse_transform(X_reduced_inc)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.subplot(121)\n",
        "plot_digits(X_train[::2100])\n",
        "plt.title(\"Original\")\n",
        "plt.subplot(122)\n",
        "plot_digits(X_recovered_inc[::2100])\n",
        "plt.title(\"Recovered (IncPCA)\")\n",
        "plt.tight_layout()\n",
        "save_fig(\"mnist_inc_pca_recovery\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NLh74yytngrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduksi awal dengan PCA full\n",
        "pca = PCA(n_components=154)\n",
        "X_reduced_pca = pca.fit_transform(X_train)\n",
        "\n",
        "# Perbandingan\n",
        "print(\"Mean sama:\", np.allclose(pca.mean_, inc_pca.mean_))\n",
        "print(\"Transformasi hasil hampir sama:\", np.allclose(X_reduced_pca, X_reduced_inc))\n",
        "\n",
        "filename = \"my_mnist.data\"\n",
        "m, n = X_train.shape\n",
        "np.memmap(filename, dtype='float32', mode='write', shape=(m, n))[:] = X_train\n",
        "del X_train  # untuk menghemat RAM\n",
        "\n",
        "X_mm = np.memmap(filename, dtype='float32', mode='readonly', shape=(m, n))\n",
        "inc_pca = IncrementalPCA(n_components=154, batch_size=m // n_batches)\n",
        "inc_pca.fit(X_mm)"
      ],
      "metadata": {
        "id": "oaivsGbLnlMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n_components in (2, 10, 154):\n",
        "    print(f\"\\nn_components = {n_components}\")\n",
        "    for name, pca in [\n",
        "        (\"PCA\", PCA(n_components=n_components, svd_solver=\"full\")),\n",
        "        (\"Inc PCA\", IncrementalPCA(n_components=n_components, batch_size=500)),\n",
        "        (\"Rnd PCA\", PCA(n_components=n_components, svd_solver=\"randomized\", random_state=42)),\n",
        "    ]:\n",
        "        t1 = time.time()\n",
        "        pca.fit(X_mm)\n",
        "        t2 = time.time()\n",
        "        print(f\"    {name:8}: {t2 - t1:.2f} seconds\")"
      ],
      "metadata": {
        "id": "OI4XEdKInodt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = [1000, 10000, 20000, 30000, 40000, 50000, 70000, 100000, 200000, 500000]\n",
        "times_rpca, times_pca = [], []\n",
        "\n",
        "for n_samples in sizes:\n",
        "    X = np.random.randn(n_samples, 5)\n",
        "    for method, times in [(\"randomized\", times_rpca), (\"full\", times_pca)]:\n",
        "        pca = PCA(n_components=2, svd_solver=method, random_state=42)\n",
        "        t0 = time.time(); pca.fit(X); times.append(time.time() - t0)\n",
        "\n",
        "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
        "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
        "plt.xlabel(\"n_samples\"); plt.ylabel(\"Time (s)\"); plt.legend()\n",
        "plt.title(\"Time vs Sample Size\"); save_fig(\"pca_vs_rpca_sample\"); plt.show()"
      ],
      "metadata": {
        "id": "0BNIDvOanqd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = [1000, 2000, 3000, 4000, 5000, 6000]\n",
        "times_rpca, times_pca = [], []\n",
        "\n",
        "for n_features in sizes:\n",
        "    X = np.random.randn(2000, n_features)\n",
        "    for method, times in [(\"randomized\", times_rpca), (\"full\", times_pca)]:\n",
        "        pca = PCA(n_components=2, svd_solver=method, random_state=42)\n",
        "        t0 = time.time(); pca.fit(X); times.append(time.time() - t0)\n",
        "\n",
        "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
        "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
        "plt.xlabel(\"n_features\"); plt.ylabel(\"Time (s)\"); plt.legend()\n",
        "plt.title(\"Time vs Feature Size\"); save_fig(\"pca_vs_rpca_feature\"); plt.show()"
      ],
      "metadata": {
        "id": "IQBUWwu_nr_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel PCA"
      ],
      "metadata": {
        "id": "6IkcnaDInwAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_swiss_roll\n",
        "from sklearn.decomposition import KernelPCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Fungsi simpan gambar\n",
        "def save_fig(fig_id, tight_layout=True, ext=\"png\", dpi=300):\n",
        "    path = os.path.join(\"images\", \"dim_reduction\", f\"{fig_id}.{ext}\")\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=ext, dpi=dpi)\n",
        "\n",
        "# Data Swiss Roll\n",
        "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)\n",
        "y = t > 6.9  # untuk klasifikasi visual"
      ],
      "metadata": {
        "id": "k2LR520pnwmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting a Kernel and Tuning Hyperparameters"
      ],
      "metadata": {
        "id": "JywCC9APnzQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup KernelPCA untuk 3 jenis kernel\n",
        "lin_pca = KernelPCA(n_components=2, kernel=\"linear\", fit_inverse_transform=True)\n",
        "rbf_pca = KernelPCA(n_components=2, kernel=\"rbf\", gamma=0.0433, fit_inverse_transform=True)\n",
        "sig_pca = KernelPCA(n_components=2, kernel=\"sigmoid\", gamma=0.001, coef0=1, fit_inverse_transform=True)\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "for subplot, pca, title in (\n",
        "    (131, lin_pca, \"Linear Kernel\"),\n",
        "    (132, rbf_pca, \"RBF Kernel, $\\gamma=0.0433$\"),\n",
        "    (133, sig_pca, \"Sigmoid Kernel, $\\gamma=10^{-3}, r=1$\")):\n",
        "\n",
        "    X_reduced = pca.fit_transform(X)\n",
        "    if subplot == 132:  # Simpan untuk inverse plot\n",
        "        X_reduced_rbf = X_reduced\n",
        "\n",
        "    plt.subplot(subplot)\n",
        "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot, s=10)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"$z_1$\", fontsize=16)\n",
        "    if subplot == 131:\n",
        "        plt.ylabel(\"$z_2$\", fontsize=16, rotation=0)\n",
        "    plt.grid(True)\n",
        "\n",
        "save_fig(\"kernel_pca_plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v_RwCCGin0GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_inverse = rbf_pca.inverse_transform(X_reduced_rbf)\n",
        "\n",
        "fig = plt.figure(figsize=(6, 5))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.view_init(10, -70)\n",
        "ax.scatter(X_inverse[:, 0], X_inverse[:, 1], X_inverse[:, 2], c=t, cmap=plt.cm.hot, marker=\"x\")\n",
        "ax.set_xticklabels([]); ax.set_yticklabels([]); ax.set_zticklabels([])\n",
        "ax.set_xlabel(\"\"); ax.set_ylabel(\"\"); ax.set_zlabel(\"\")\n",
        "\n",
        "save_fig(\"preimage_plot\", tight_layout=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Yael-pvn3dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_reduced = rbf_pca.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot, marker=\"x\")\n",
        "plt.xlabel(\"$z_1$\", fontsize=16)\n",
        "plt.ylabel(\"$z_2$\", fontsize=16, rotation=0)\n",
        "plt.grid(True)\n",
        "save_fig(\"kernel_rbf_projection\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HzVPF-aqn43W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLE dan Other Dimensionality Reduction Techniques"
      ],
      "metadata": {
        "id": "53-12ILmn762"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Pipeline + GridSearchCV\n",
        "clf = Pipeline([\n",
        "    (\"kpca\", KernelPCA(n_components=2)),\n",
        "    (\"log_reg\", LogisticRegression(solver=\"lbfgs\"))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
        "    \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
        "grid_search.fit(X, y)  # dari swiss roll: y = t > 6.9"
      ],
      "metadata": {
        "id": "eWx_QVWRn-J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbf_pca = KernelPCA(n_components=2, kernel=\"rbf\", gamma=0.0433, fit_inverse_transform=True)\n",
        "X_reduced = rbf_pca.fit_transform(X)\n",
        "X_preimage = rbf_pca.inverse_transform(X_reduced)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"MSE preimage:\", mean_squared_error(X, X_preimage))\n",
        "\n",
        "from sklearn.datasets import make_swiss_roll\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "\n",
        "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=41)\n",
        "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)\n",
        "X_reduced = lle.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.title(\"Unrolled Swiss Roll (LLE)\", fontsize=14)\n",
        "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot)\n",
        "plt.xlabel(\"$z_1$\"); plt.ylabel(\"$z_2$\"); plt.grid(True)\n",
        "plt.axis([-0.065, 0.055, -0.1, 0.12])\n",
        "save_fig(\"lle_unrolling_plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jG0dX8dln-l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import MDS, Isomap, TSNE\n",
        "\n",
        "mds = MDS(n_components=2, random_state=42)\n",
        "isomap = Isomap(n_components=2)\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "\n",
        "X_mds = mds.fit_transform(X)\n",
        "X_iso = isomap.fit_transform(X)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "titles = [\"MDS\", \"Isomap\", \"t-SNE\"]\n",
        "embeddings = [X_mds, X_iso, X_tsne]\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "for subplot, title, X_red in zip((131, 132, 133), titles, embeddings):\n",
        "    plt.subplot(subplot)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.scatter(X_red[:, 0], X_red[:, 1], c=t, cmap=plt.cm.hot)\n",
        "    plt.xlabel(\"$z_1$\")\n",
        "    if subplot == 131:\n",
        "        plt.ylabel(\"$z_2$\", rotation=0)\n",
        "    plt.grid(True)\n",
        "\n",
        "save_fig(\"other_dim_reduction_plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f1OnZ9gboERW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Konversi label menjadi integer\n",
        "X_mnist = mnist[\"data\"]\n",
        "y_mnist = mnist[\"target\"].astype(np.uint8)  # ← penting!\n",
        "\n",
        "# LDA dengan 2 komponen\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "X_reduced_lda = lda.fit_transform(X_mnist, y_mnist)\n",
        "\n",
        "# Visualisasi\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(X_reduced_lda[:, 0], X_reduced_lda[:, 1], c=y_mnist, cmap=\"jet\", alpha=0.5)\n",
        "plt.title(\"LDA on MNIST\")\n",
        "plt.xlabel(\"$z_1$\")\n",
        "plt.ylabel(\"$z_2$\", rotation=0)\n",
        "plt.grid(True)\n",
        "save_fig(\"lda_mnist_plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-nH8TsyzoFXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Proses Reduksi Dimensi & Evaluasi**"
      ],
      "metadata": {
        "id": "6wkXffRXoG62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PCA (Principal Component Analysis)\n",
        "Digunakan untuk mereduksi dimensi dataset MNIST.\n",
        "Menentukan jumlah komponen optimal berdasarkan explained variance ratio.\n",
        "Titik elbow digunakan untuk mengidentifikasi jumlah komponen yang mempertahankan ≥95% variansi.\n",
        "Visualisasi cumulative sum membantu dalam menganalisis kontribusi variansi secara keseluruhan.\n",
        "\n",
        "## 2. Incremental PCA\n",
        "Merupakan alternatif PCA untuk dataset besar yang tidak dapat dimuat sekaligus ke dalam memori.\n",
        "Dilakukan secara bertahap dalam bentuk batch-wise learning.\n",
        "Hasil yang diperoleh serupa dengan PCA konvensional, sehingga cocok untuk data skala besar seperti MNIST.\n",
        "Penggunaan memmap meningkatkan efisiensi penggunaan memori.\n",
        "\n",
        "## 3. Randomized PCA\n",
        "Mempercepat proses dekomposisi SVD dengan pendekatan aproksimasi berbasis acak.\n",
        "Lebih efisien dibanding PCA konvensional (full SVD), terutama pada dataset berdimensi besar.\n",
        "Dievaluasi berdasarkan waktu pelatihan terhadap variasi jumlah sampel dan fitur.\n",
        "\n",
        "## 4. Perbandingan Waktu Eksekusi PCA\n",
        "Randomized PCA menunjukkan waktu eksekusi yang jauh lebih cepat dibanding PCA biasa pada skala besar.\n",
        "Kompleksitas waktu meningkat signifikan seiring bertambahnya jumlah fitur dan sampel.\n",
        "Hasil visualisasi menampilkan perbandingan kurva waktu eksekusi dari berbagai metode PCA.\n",
        "\n",
        "## 5. Kernel PCA\n",
        "Digunakan untuk menangani data nonlinier (contoh: Swiss Roll).\n",
        "Tiga jenis kernel dibandingkan: Linear, RBF, dan Sigmoid.\n",
        "Kernel RBF terbukti paling efektif dalam membuka struktur manifold nonlinier."
      ],
      "metadata": {
        "id": "wGScFTqXoLDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Preimage Reconstruction\n",
        "Kernel PCA dengan RBF mendukung proses rekonstruksi balik (inverse transform).\n",
        "Evaluasi dilakukan dengan menghitung Mean Squared Error (MSE) antara data asli dan hasil rekonstruksi.\n",
        "Menunjukkan sejauh mana informasi penting tetap dipertahankan setelah reduksi.\n",
        "\n",
        "## 7. LLE (Locally Linear Embedding)\n",
        "Digunakan untuk memproyeksikan data manifold kompleks ke dalam ruang 2D (contoh: Swiss Roll).\n",
        "Mampu mempertahankan struktur lokal dengan baik.\n",
        "Cocok untuk eksplorasi dan visualisasi data nonlinier.\n",
        "\n",
        "## 8. Metode Reduksi Dimensi Nonlinier Lainnya\n",
        "\n",
        "* MDS (Multidimensional Scaling): mempertahankan jarak absolut antar instance.\n",
        "\n",
        "* Isomap: mempertahankan jarak geodesik, memperluas pendekatan MDS.\n",
        "\n",
        "* t-SNE: sangat efektif untuk visualisasi klaster, namun tidak cocok untuk prediksi karena tidak mendukung transformasi balik.\n",
        "Setiap metode memiliki keunikan dalam memetakan data berdimensi tinggi ke ruang berdimensi rendah.\n",
        "\n",
        "## 9. LDA (Linear Discriminant Analysis)\n",
        "Merupakan teknik supervised dimensionality reduction.\n",
        "Menggunakan informasi label kelas untuk memaksimalkan separabilitas antar kelas.\n",
        "Diterapkan pada dataset MNIST dan menghasilkan visualisasi pemisahan digit yang baik."
      ],
      "metadata": {
        "id": "Zbbp--FYoZuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kesimpulan**\n",
        "PCA dan variannya (Incremental PCA dan Randomized PCA) sangat efektif untuk data berukuran besar dan struktur linier. Untuk data nonlinier, Kernel PCA (khususnya dengan kernel RBF) merupakan pilihan yang kuat. Metode seperti LLE, Isomap, MDS, dan t-SNE unggul dalam visualisasi struktur manifold nonlinier. LDA sangat optimal dalam konteks klasifikasi karena mempertahankan informasi yang bersifat diskriminatif. Pemilihan teknik reduksi dimensi sebaiknya disesuaikan dengan tujuan utama: efisiensi komputasi, interpretabilitas, visualisasi, atau klasifikasi."
      ],
      "metadata": {
        "id": "3k8uZClhokY-"
      }
    }
  ]
}
