{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjH0Ee7J1ZsvBi8VXqRFlV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhiqbalalamin/DeepLearning-UAS/blob/main/Chapter_13_Teori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and Preprocessing Data with TensorFlow**"
      ],
      "metadata": {
        "id": "USbi4kUzGqn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tujuan Bab\n",
        "Bab ini membahas cara:\n",
        "\n",
        "* Memuat data secara efisien menggunakan tf.data\n",
        "\n",
        "* Melakukan prapemrosesan data secara modular dan skalabel\n",
        "\n",
        "* Mengoptimalkan pipeline input untuk performa maksimal\n",
        "\n",
        "## Tantangan dalam Pipeline Data Input\n",
        "1. Dataset berukuran besar tidak dapat dimuat seluruhnya ke dalam memori.\n",
        "\n",
        "2. Dibutuhkan proses prapemrosesan yang cepat dan konsisten.\n",
        "\n",
        "3. Pelatihan model yang efisien memerlukan pipeline input yang dioptimalkan.\n",
        "\n",
        "## API tf.data\n",
        "TensorFlow menyediakan API tf.data untuk:\n",
        "\n",
        "* Membuat objek Dataset\n",
        "\n",
        "* Melakukan transformasi data\n",
        "\n",
        "* Menangani pipeline streaming secara efisien (lazy evaluation)\n",
        "\n",
        "## Pembuatan Dataset\n",
        "Beberapa cara umum:\n",
        "\n",
        "* Dari array: from_tensor_slices()\n",
        "\n",
        "* Dari file: TextLineDataset, TFRecordDataset\n",
        "\n",
        "* Dari generator Python\n",
        "\n",
        "## Transformasi Dataset\n",
        "Objek Dataset bersifat lazy, artinya transformasi dilakukan hanya saat dibutuhkan.\n",
        "\n",
        "Transformasi umum meliputi:\n",
        "\n",
        "* map(): menerapkan transformasi pada tiap elemen\n",
        "\n",
        "* filter(): menyaring elemen berdasarkan kondisi\n",
        "\n",
        "* batch(): mengelompokkan data ke dalam batch\n",
        "\n",
        "* shuffle(): mengacak urutan data\n",
        "\n",
        "* repeat(): mengulang dataset"
      ],
      "metadata": {
        "id": "AqteL4DSGsxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimalisasi Performa Pipeline\n",
        "### Prefetching\n",
        "prefetch(n) memungkinkan proses pemuatan data dan pelatihan berjalan secara paralel.\n",
        "\n",
        "### Interleaving & Parallel Mapping\n",
        "* interleave(): membaca banyak file secara bersamaan\n",
        "\n",
        "* map(..., num_parallel_calls=tf.data.AUTOTUNE): memproses data secara paralel\n",
        "\n",
        "## Caching\n",
        "cache() menyimpan hasil transformasi agar tidak dihitung ulang di setiap epoch.\n",
        "\n",
        "### Format Data: TFRecord\n",
        "TFRecord adalah format biner yang efisien untuk menyimpan data dalam skala besar:\n",
        "\n",
        "* Kompresi tinggi\n",
        "\n",
        "* Akses cepat\n",
        "\n",
        "* Cocok untuk produksi (digunakan oleh Google dan TFX)\n",
        "\n",
        "Digunakan bersama dengan:\n",
        "\n",
        "* TFRecordDataset\n",
        "\n",
        "* tf.train.Example (untuk parsing protokol buffer)"
      ],
      "metadata": {
        "id": "qzvklIbUHmvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing dan Decoding TFRecord\n",
        "Setelah data dibaca dari file TFRecord, perlu di-decode agar dapat digunakan kembali sesuai struktur aslinya.\n",
        "\n",
        "### Contoh decoding:\n",
        "* Gambar:\n",
        "\n",
        "    * JPEG → tf.io.decode_jpeg()\n",
        "\n",
        "    * PNG → tf.io.decode_png()\n",
        "\n",
        "* Teks atau bytes:\n",
        "\n",
        "    * tf.io.decode_raw()\n",
        "\n",
        "* Label numerik:\n",
        "\n",
        "    * Gunakan tf.cast() ke tf.int64 atau tf.float32\n",
        "\n",
        "* Parsing TFRecord:\n",
        "\n",
        "feature_description = {\n",
        "  'image': tf.io.FixedLenFeature([], tf.string),\n",
        "  'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "}\n",
        "\n",
        "parsed_example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "\n",
        "## Prapemrosesan Data (Preprocessing)\n",
        "Transformasi umum sebelum data masuk ke model:\n",
        "\n",
        "* Normalisasi: skala nilai ke rentang 0–1\n",
        "\n",
        "* Standarisasi: mengurangkan rata-rata dan membagi dengan standar deviasi\n",
        "\n",
        "* Resizing: menyesuaikan ukuran gambar (misalnya menjadi 224x224 piksel)\n",
        "\n",
        "* Augmentasi: rotasi, flipping, cropping, zoom untuk memperkuat generalisasi model\n",
        "\n",
        "* Tokenisasi: memecah teks menjadi unit kata/karakter\n",
        "\n",
        "* Padding: menyamakan panjang input teks dalam batch"
      ],
      "metadata": {
        "id": "46qUBlfmH5Hb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lokasi Preprocessing\n",
        "1. Offline\n",
        "Dilakukan sebelum pelatihan dan disimpan ke disk (dalam format .npy, TFRecord, dll).\n",
        "\n",
        "2. Di dalam pipeline tf.data\n",
        "Menggunakan fungsi map() untuk menerapkan transformasi secara on-the-fly.\n",
        "\n",
        "3. Di dalam model\n",
        "Menggunakan layer seperti Rescaling, Resizing, TextVectorization.\n",
        "\n",
        "## Perbandingan Lokasi Preprocessing\n",
        "| Lokasi             | Keunggulan                              | Kelemahan                             |\n",
        "| ------------------ | --------------------------------------- | ------------------------------------- |\n",
        "| **Di dalam model** | Portabel, bisa dibawa saat *deployment* | Dapat memperlambat proses inferensi   |\n",
        "| **Dalam pipeline** | Cepat, fleksibel selama pelatihan       | Tidak otomatis ikut saat ekspor model |\n",
        "| **Offline**        | Konsisten, mudah didistribusikan        | Tidak fleksibel jika data berubah     |\n"
      ],
      "metadata": {
        "id": "eiLUGoAeIWdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimalisasi Pipeline\n",
        "Untuk efisiensi maksimal, urutan transformasi yang disarankan adalah:\n",
        "\n",
        "Load → Shuffle → Cache → Batch → Prefetch\n",
        "\n",
        "## TensorFlow Extended (TFX)\n",
        "TFX adalah platform produksi untuk machine learning berbasis TensorFlow, yang mendukung pipeline skala besar dari awal hingga deployment.\n",
        "\n",
        "## Komponen Utama TFX:\n",
        "* ExampleGen: mengimpor dan mengonversi data ke format TFRecord\n",
        "\n",
        "* StatisticsGen: menghasilkan statistik dataset\n",
        "\n",
        "* SchemaGen: membuat skema fitur berdasarkan statistik\n",
        "\n",
        "* ExampleValidator: mendeteksi data yang rusak, hilang, atau anomali\n",
        "\n",
        "* Transform: melakukan prapemrosesan berskala besar dengan TensorFlow Transform (TFT)\n",
        "\n",
        "* Trainer: melatih model dengan Keras atau Estimator\n",
        "\n",
        "* Tuner (opsional): optimasi otomatis hyperparameter\n",
        "\n",
        "* Evaluator: mengevaluasi performa model\n",
        "\n",
        "* InfraValidator: memastikan model dapat disajikan sebelum deployment\n",
        "\n",
        "* Pusher: men-deploy model ke TensorFlow Serving atau sistem lainnya"
      ],
      "metadata": {
        "id": "7tmtIhXpIcyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rumus dan Konsep Kunci\n",
        "### Normalisasi\n",
        "\n",
        "\\[\n",
        "$x_{\\text{norm}} = \\frac{x - \\mu}{\\sigma}$\n",
        "\\]\n",
        "\n",
        "- \\($ x $\\): nilai asli\n",
        "- \\($ \\mu $\\): rata-rata\n",
        "- \\($ \\sigma $\\): deviasi standar\n",
        "\n",
        "### Ukuran Buffer Shuffle\n",
        "* Buffer yang lebih besar → pengacakan data lebih merata\n",
        "\n",
        "* Ideal jika buffer_size >= jumlah data, selama memori mencukupi\n",
        "\n",
        "## Pipeline tf.data yang Dioptimalkan\n",
        "Gunakan transformasi berikut dalam urutan yang direkomendasikan:\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size)\n",
        "                 .cache()\n",
        "                 .batch(batch_size)\n",
        "                 .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "* shuffle(): mencegah model menghafal urutan data\n",
        "\n",
        "* cache(): menyimpan hasil transformasi agar tidak diulang\n",
        "\n",
        "* batch(): mempercepat pelatihan dengan proses paralel\n",
        "\n",
        "*prefetch(): memperlancar alur antara CPU dan GPU"
      ],
      "metadata": {
        "id": "dgoy9ZarIz49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kesimpulan**\n",
        "* API tf.data menawarkan pipeline data yang efisien dan dapat diskalakan, cocok untuk berbagai skenario — dari eksperimen lokal hingga pelatihan skala besar.\n",
        "\n",
        "* Format TFRecord sangat cocok untuk penyimpanan data dan pelatihan produksi.\n",
        "\n",
        "* Prapemrosesan dapat dilakukan secara offline, di pipeline tf.data, atau langsung di dalam model — masing-masing memiliki kelebihan dan kekurangan.\n",
        "\n",
        "* Gunakan TFX untuk membangun pipeline machine learning end-to-end secara terstandar dan andal.\n",
        "\n",
        "* Optimalisasi pipeline input sangat penting untuk efisiensi waktu pelatihan dan pemanfaatan sumber daya secara maksimal.\n",
        "\n",
        "# **Referensi**\n",
        "Géron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly Media."
      ],
      "metadata": {
        "id": "vh-qlbI0JEOD"
      }
    }
  ]
}
